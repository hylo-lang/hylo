import Driver
import FrontEnd
import Utils
import XCTest

extension Diagnostic {

  /// A test annotation that announces `self` should be expected.
  fileprivate var expectation: TestAnnotation {
    TestAnnotation(
      in: site.file.url,
      atLine: site.start.line.number,
      parsing: "diagnostic " + message
    )
  }

}

extension Result {

  /// The success value, if any, and `nil` otherwise.
  var success: Success? {
    if case .success(let r) = self { return r } else { return nil }
  }

  /// The failure value, if any, and `nil` otherwise.
  var failure: Failure? {
    if case .failure(let r) = self { return r } else { return nil }
  }

}

extension XCTestCase {

  /// The effects of running the `processAndCheck` parameter to `checkAnnotatedHyloFiles`.
  fileprivate typealias ProcessingEffects = (
    /// Test failures generated by processing.
    testFailures: [XCTIssue],
    /// Hylo diagnostics generated by processing.
    diagnostics: DiagnosticSet
  )

  /// Applies `processAndCheck` to `hyloToTest` and the subset of its annotations whose commands
  /// match `checkedCommands`, recording resulting XCTest failures along with any additional
  /// failures where the effects of processing don't match the its annotation commands ("//!
  /// ... diagnostic ..."), and returning any error thrown by `processAndCheck`.
  ///
  /// - Parameters:
  ///   - checkedCommands: the annnotation commands to be validated by `processAndCheck`.
  ///   - processAndCheck: applies some compilation phases to `file`, updating `diagnostics`
  ///     with any generated diagnostics, then checks `annotationsToCheck` against the results,
  ///     returning corresponding test failures. Throws an `Error` if any phases failed.
  fileprivate func checkAnnotations(
    in hyloToTest: SourceFile,
    checkingAnnotationCommands checkedCommands: Set<String> = [],
    _ processAndCheck: (
      _ file: SourceFile,
      _ annotationsToCheck: ArraySlice<TestAnnotation>,
      _ diagnostics: inout DiagnosticSet
    ) throws -> [XCTIssue]
  ) -> Error? {
    var annotations = TestAnnotation.parseAll(from: hyloToTest)

    // Separate the annotations to be checked by default diagnostic annotation checking from
    // those to be checked by `processAndCheck`.
    let p = annotations.partition(by: { checkedCommands.contains($0.command) })
    let (diagnosticAnnotations, processingAnnotations) = (annotations[..<p], annotations[p...])

    var diagnostics = DiagnosticSet()
    var thrownError: Error? = nil

    let failures = XCTContext.runActivity(
      named: hyloToTest.baseName,
      block: { activity in
        let r = Result { try processAndCheck(hyloToTest, processingAnnotations, &diagnostics) }
        thrownError = r.failure

        return failuresToReport(
          effectsOfProcessing: (
            testFailures: r.success ?? [],
            diagnostics: diagnostics
          ),
          unhandledAnnotations: diagnosticAnnotations)
      })

    for f in failures {
      record(f)
    }

    return thrownError
  }

  /// Applies `process` to the ".hylo" file at the given path and reports XCTest failures where the
  /// effects of processing don't match the file's annotation commands ("//! ... diagnostic ...").
  ///
  /// - Parameters:
  ///   - process: applies some processing to `file`, updating `diagnostics` with any generated
  ///     diagnostics. Throws an `Error` if processing failed.
  ///   - expectSuccess: true if an error from `process` represents a test failure, false if the
  ///     lack of an error represents a test failure; nil if that information is to be derived
  ///     from the contents of the file.
  @nonobjc
  public func checkAnnotatedHyloFileDiagnostics(
    inFileAt hyloFilePath: String,
    expectSuccess: Bool,
    _ process: (_ file: SourceFile, _ diagnostics: inout DiagnosticSet) throws -> Void
  ) throws {
    let f = try SourceFile(at: hyloFilePath)

    // FIXME: clarify/explain this code
    let thrownError = checkAnnotations(in: f, checkingAnnotationCommands: []) {
      (f, annotationsToHandle, diagnostics) in
      assert(annotationsToHandle.isEmpty)
      try process(f, &diagnostics)
      return []
    }

    if (thrownError == nil) != expectSuccess {
      record(XCTIssue(unexpectedOutcomeDiagnostic(thrownError: thrownError, at: f.wholeRange)))
    }
  }

  /// Returns the diagnostic of an unexpected outcome with given `thrownError` reported at `s`.
  private func unexpectedOutcomeDiagnostic(thrownError: Error?, at s: SourceRange) -> Diagnostic {
    if let e = thrownError {
      return .error("success was expected, but processing failed with thrown error: \(e)", at: s)
    } else {
      return .error("processing succeeded, but failure was expected", at: s)
    }
  }

  /// Given the effects of processing, the annotations not specifically handled by `processAndCheck`
  /// above, returns the final set of test failures to be reported to XCTest.
  fileprivate func failuresToReport(
    effectsOfProcessing processing: ProcessingEffects,
    unhandledAnnotations: ArraySlice<TestAnnotation>
  ) -> [XCTIssue] {
    var testFailures = processing.testFailures

    var diagnosticsByExpectation = Dictionary(
      grouping: processing.diagnostics.elements, by: \.expectation)

    func fail(_ expectation: TestAnnotation, _ message: String) {
      testFailures.append(expectation.failure(message))
    }

    for a in unhandledAnnotations {
      switch a.command {
      case "diagnostic":
        if diagnosticsByExpectation[a]?.popLast() != nil {
        } else {
          fail(a, "missing expected diagnostic\(a.argument.map({": '\($0)'"}) ?? "")")
        }
      case "expect-failure": do {}
      case "expect-success": do {}
      default:
        fail(a, "unexpected test command: '\(a.command)'")
      }
    }

    testFailures += diagnosticsByExpectation.values.joined().lazy.map {
      XCTIssue(.error("unexpected diagnostic: '\($0.message)'", at: $0.site, notes: $0.notes))
    }
    return testFailures
  }

  /// Calls `compileAndRun(hyloFilePath, withOptimizations: false, expectSuccess: expectSuccess)`.
  @nonobjc
  public func compileAndRun(_ hyloFilePath: String, expectSuccess: Bool) throws {
    try compileAndRun(hyloFilePath, withOptimizations: false, expectSuccess: expectSuccess)
  }

  /// Calls `compileAndRun(hyloFilePath, withOptimizations: true, expectSuccess: expectSuccess)`.
  @nonobjc
  public func compileAndRunWithOptimizations(_ hyloFilePath: String, expectSuccess: Bool) throws {
    try compileAndRun(hyloFilePath, withOptimizations: true, expectSuccess: expectSuccess)
  }

  /// Compiles and runs the hylo file at `hyloFilePath`, applying program optimizations iff
  /// `withOptimizations` is `true`, and `XCTAssert`ing that diagnostics and exit codes match
  /// annotated expectations.
  @nonobjc
  public func compileAndRun(
    _ hyloFilePath: String, withOptimizations: Bool, expectSuccess: Bool
  ) throws {
    if swiftyLLVMMandatoryPassesCrash { return }
    try checkAnnotatedHyloFileDiagnostics(
      inFileAt: hyloFilePath, expectSuccess: expectSuccess
    ) { (hyloSource, diagnostics) in
      try compileAndRun(
        hyloSource, withOptimizations: withOptimizations, reportingDiagnosticsTo: &diagnostics)
    }
  }

  /// Compiles and runs `hyloSource`, applying program optimizations iff `withOptimizations` is
  /// `true`, and `XCTAssert`ing that diagnostics and exit codes match annotated expectations.
  private func compileAndRun(
    _ hyloSource: SourceFile, withOptimizations: Bool,
    reportingDiagnosticsTo diagnostics: inout DiagnosticSet
  ) throws {
    var arguments = ["--emit", "binary"]
    if withOptimizations { arguments.append("-O") }

    var executable: URL
    do {
      executable = try compile(hyloSource.url, with: arguments)
    } catch let d as DiagnosticSet {
      // Recapture the diagnostics so the annotation testing framework can use them.  The need for
      // this ugliness makes me wonder how important it is to test cli.execute, which after all is
      // just a thin wrapper over cli.executeCommand (currently private).
      diagnostics = d
      throw d
    }

    // discard any outputs.
    _ = try Process.run(executable, arguments: [])
  }

  /// Compiles the hylo file at `hyloFilePath` up until emitting LLVM code, `XCTAssert`ing that diagnostics and exit
  /// codes match annotated expectations.
  @nonobjc
  public func compileToLLVM(_ hyloFilePath: String, expectSuccess: Bool) throws {
    if swiftyLLVMMandatoryPassesCrash { return }
    try checkAnnotatedHyloFileDiagnostics(inFileAt: hyloFilePath, expectSuccess: expectSuccess) {
      (hyloSource, diagnostics) in

      do {
        let _ = try compile(hyloSource.url, with: ["--emit", "llvm"])
      } catch let d as DiagnosticSet {
        // Recapture the diagnostics so the annotation testing framework can use them.  The need for
        // this ugliness makes me wonder how important it is to test cli.execute, which after all is
        // just a thin wrapper over cli.executeCommand (currently private).
        diagnostics = d
        throw d
      }
    }
  }

  /// Compiles `input` with the given arguments and returns the URL of the output file, throwing
  /// diagnostics if there are any errors.
  @nonobjc
  public func compile(_ input: URL, with arguments: [String]) throws -> URL {
    let output = FileManager.default.makeTemporaryFileURL()
    let cli = try Driver.parse(arguments + ["-o", output.relativePath, input.relativePath])
    let (status, diagnostics) = try cli.execute()
    if !status.isSuccess {
      throw diagnostics
    }

    XCTAssert(
      !diagnostics.containsError,
      "CLI reported success but \(input) contains errors: \(diagnostics.rendered())")

    #if os(Windows)
      let executableSuffix = ".exe"
    #else
      let executableSuffix = ""
    #endif

    XCTAssert(
      FileManager.default.fileExists(atPath: output.relativePath + executableSuffix),
      "Compilation output file not found: \(output.relativePath)")

    return output
  }

}
